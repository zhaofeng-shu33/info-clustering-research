\documentclass{article}
\usepackage{subcaption}
\input{macros.tex}
\title{Improved Algorithm of PSP}
\begin{document}
\maketitle

In the original formulation to calculate principal sequence of partition. A Divide and Conquer approach is used and $\min_{\P} \{f[\P]-\lambda \abs{\P}\}$ is evaluated only at finite $\lambda$. However, computation for different $\lambda$ is independent and does not use the nesting property of the PSP. Therefore, we propose an improved version of PSP, which utilizes the nesting property to decrease the time complexity of the algorithm.

Generally speaking, we first solve $\min_{\P} \{ f[\P]-\lambda \abs{\P} \}$ at $\lambda_1 = \frac{w}{\abs{V}-1}$ where $w$ is the summation of all edge capacity. Then for those $\lambda > \lambda_1$ we do not need to compute for the whole graph $G$. Suppose $\P_1 = \argmin_{\P} \{ f[\P]-\lambda \abs{\P} \}$ and for each $ C \in \P_1$, it is sufficient to consider subgraph $G'$ constraint on node set $C$. That is, we compute the clustering tree starting with tree root $C$ instead of $V$. For $\lambda < \lambda_1$, a graph contraction technique can be used. That is, the graph $G$ can be contracted to $\abs{\P_1}$ parts and the same algorithm can be run with the same root node $V$ but it has different children this time (previously, all children of $V$ is $\{j\}$, afterwards it is $C$ for $C \in \P_1$.

The tricky part of the implementation is how to construct the whole clustering tree $\mathcal{T}$.

\begin{algorithm}
\caption{A Fast Algorithm to Compute the Hierarchical Tree of Info-Clustering}\label{alg:psp_a}
\begin{algorithmic}[1]
\REQUIRE a directed graph $G(V, E)$; edge cost function $c(e)$ for $e\in E$
\ENSURE a hierarchical tree $\mathcal{T}(K, E)$ where $K$ is node set and $E$ is edge set; $c'$ as edge weight map. Each non-leaf node of $\mathcal{T}$ is an info-cluster and each edge weight is a critical value. 
\STATE initialize a set list $K=[V, \{1\}, \dots, \{V\}]$, a tree $\mathcal{T}$ with 0 as root node, $j(j\leq \abs{V})$ as leaf node and no stem node.
\STATE \texttt{Split}(0)
\FUNCTION{\texttt{Split}$(i)$}
\STATE Let $T=\{K[j][0] | \texttt{parent}(j) = i\}$
\STATE Consider subgraph $G'$ constraint on set $T$. $w$ is the summation of all edge weights within $G'$ 
\STATE $\gamma' = \frac{w}{\abs{T}-1}$ \label{line:intersection}  \label{alg:T}
\STATE $(\tilde{h}, P') = \texttt{DT}(G', \gamma')$
\IF{$\tilde{h} = - \gamma'$}
\STATE add edge weight $\gamma'$ starting from $i$ to its children. \label{alg:add_lambda}
\ELSE
\FOR{$S$ in $P'$ and $\abs{S}>1$}
\STATE Let $S'=S$, $s=\abs{K}$% index(S) = |K|
\FOR{child $j$ of $i$}
\IF{$K[j]\cap S \neq \emptyset$}
\STATE \texttt{parent}$(j)=s, S'=S'\cup K[j]$
\ENDIF
\ENDFOR
\STATE \texttt{parent}$(s)=i$, append $S'$ to $K$
\STATE \texttt{Split}(s)
\STATE within the graph $G$, contract $S$ to $S$[0]
\ENDFOR
\STATE \texttt{Split}$(i)$ % the graph is modified
\ENDIF
\ENDFUNCTION
\end{algorithmic}
\end{algorithm}
In line \ref{line:intersection}, since we are considering the intersection of $-\lambda$ and $w-\abs{T}\lambda $.

To analyze the complexity of algorithm \ref{alg:psp_a}.
We use $T(n)$ to represent the time complexity when the graph has $n$ nodes. Suppose $\abs{E} = O(n^2)$. We have the following recursive relationship.
\begin{equation}
	T(n) = \max \{ O(n^4) + \sum_{i=1}^k T(n_i) + T(k) | \sum_{i=1}^k n_i = n, n_i \in \mathbb{Z}_{+} \}
\end{equation}	
\begin{lemma}
	$\gamma'$ is the weighted average of all critical values of PSP.
\end{lemma}	
\begin{proof}
	Using the agglomerative view, we can get a successively increasing set $\emptyset = S_0 \subsetneq S_1 \subsetneq S_2 \subsetneq \dots \subsetneq S_k$ such that $S_k = V, \gamma_i = \frac{\sum_{(i,j) \in E(S_i\backslash S_{i-1})} w_{ij}}{\abs{S_i\backslash S_{i-1}}- \delta_{i1}}$. Then we have $\gamma' = \sum_{i=1}^k \frac{\abs{S_i \backslash S_{i-1}} - \delta_{i1}}{\abs{V} - 1}\gamma_i$. Let $\lambda_i = \gamma_{k-i+1}$, then $\lambda_1 < \dots < \lambda_k$ are critical values of PSP.
\end{proof}		

Below we distinguish two cases:
\begin{enumerate}
\item Worst case scenario: suppose the hierarchical tree has such a structure that its depth is $\abs{V} - 1$.  The complexity bound is $O(3^4+4^4 + \dots + n^4) = O(\frac{1}{5} n^5)$. Although the exponent (still 5) is not improved. We have reduced the time complexity by a constant coefficient 5.
\item Average case scenario: Since $\gamma'$ is the weighted average of critical values, generally it is near to the median of these critical values. We make the assumption that $ \lambda_{\floor{k/2} - 1} \leq \gamma' \leq \lambda_{\ceil{k/2} + 1}$. Then $k < \frac{n}{2}$ and the maximal $n_i \leq \frac{n}{2}$. Let $\mu_i = \frac{n_i}{n}$. We proceed by induction to show $T(n) = O(n^4)$. Assume the time complexity of DT algorithm is $C n^4$
and $Cm^4 \leq T(m) \leq kC m^4$ holds for all $m \leq n-1$ where $k=\frac{16}{5}$. Then for $T(n)$
We first show that 
\begin{equation}\label{eq:outerI}
\sum_{i=1}^k T(n_i) \leq 10 T(\frac{n}{2})
\end{equation}
Since $\sum_{i=1}^k T(n_i) \leq kC n^4\sum_{i=1}^k u_i^4$ and $10 T(\frac{n}{2}) \geq 10Cn^4 (\frac{1}{2})^4$
\begin{equation}\label{eq:innerI}
k\sum_{i=1}^k u_i^4 \leq 10 (\frac{1}{2})^4 
\end{equation}
We have \eqref{eq:innerI} $\Rightarrow$ \eqref{eq:outerI}. The constraint is that $u_1\leq u_2 \leq \dots \leq u_k \leq \frac{1}{2}$. Therefore we have $u_1 \leq \frac{1}{k}, u_2 \leq \frac{1}{k-1}, \dots, u_{k-1} \leq \frac{1}{2}$.
\begin{equation}\label{eq:outerOne}
k[2(\frac{1}{2})^4 + \sum_{i=3}^k (\frac{1}{i})^4] \leq 10 (\frac{1}{2})^4
\end{equation}
We have \eqref{eq:outerOne} $\Rightarrow$ \eqref{eq:innerI}. And \eqref{eq:outerOne} is equivalent to
$\sum_{i=3}^k (\frac{1}{i})^4 \leq \frac{9}{8}(\frac{1}{2})^4$
\begin{align*}
	\sum_{i=3}^k (\frac{1}{i})^4 & < \frac{1}{9}\sum_{i=3}^k (\frac{1}{i})^2 \\
              & < \frac{1}{9}\sum_{i=3}^k (\frac{1}{(i-1)i}) \\
              & < \frac{1}{18} < \frac{9}{8}(\frac{1}{2})^4
\end{align*}
Therefore, \eqref{eq:outerI} holds and we have 
\begin{align}
T(n)  & \leq Cn^4 + 11T(\frac{n}{2}) \\
& \leq C n^4 + 11 k C (\frac{n}{2})^4 = \frac{16}{5} C n^4
\end{align}
\end{enumerate}
Compared with parametric algorithm, which also has $O(n^4)$ time complexity. Our algorithm has several advantages:
\begin{enumerate}
	\item Lower space complexity. The parametric algorithm uses graph contraction which should copy the graph before contraction. In the worst case, the copy should be conducted in $O(n)$ times which produces $O(n^3)$ space complexity.
	For our algorithm, the computation is done on the input graph, which has $O(n^2)$ space complexity.
	\item Robust against floating accuracy. The parametric algorithm uses flow map from the last computation. However, because of floating point accuracy. The output flow map cannot guarantee that the excess of each node (except source and sink) is exactly zero, which makes the computation harder to track and fails totally in some extreme cases. Although some tolerance can be added, there are no theoretical guarantee how to specify such tolerance.
\end{enumerate}
The idea of the improved PSP algorithm can be generalized to get a hierarchical community detection algorithm from any "flatten" algorithm ( which can only get one-level structure of a community ).

It is found that our implementation of info-clustering cannot handle very small capacity value. For a given $\epsilon$, let capacity equal to zero if it is less than $\epsilon$.

Early stopping technique, if $\abs{T}=2$ on line \ref{alg:T}, then we can skip directly to line \ref{alg:add_lambda}.

The graph contraction is summation of absolute values.

Increasing set version of  \texttt{DT} algorithm only support $(i,j) \in E \Rightarrow i<j$.

\section{Agglomerative method}
Another version of psp can be implemented agglomeratively.
\begin{algorithm}
\caption{}\label{alg:psp_agg}
\begin{algorithmic}[1]
\REQUIRE a directed graph $G(V, E)$; edge cost function $c(e)$ for $e\in E$
\ENSURE a hierarchical tree $\mathcal{T}(K, E)$ where $K$ is node set and $E$ is edge set; $c'$ as edge weight map. Each non-leaf node of $\mathcal{T}$ is an info-cluster and each edge weight is a critical value. 
\STATE initialize a set list $K=[V, \{1\}, \dots, \{V\}]$, a tree $\mathcal{T}$ with 0 as root node, $j(j\leq \abs{V})$ as leaf node and no stem node.
\STATE \texttt{Merge}(0,0)
\FUNCTION{\texttt{Merge}$(i,j)$}
\STATE $j' = \texttt{children}(i)[j]$
\STATE Compute $C^* =\displaystyle \argmax_{K[j'][0] \in C \subseteq V \cap K[i]} \frac{w(C)}{\abs{C}-1}$ where $w$ is the summation of all edge weights within set $C$. \label{line:max}
\IF{$C^* = K[i]$}
\STATE remove node $K[i][j]$ from the graph
\IF{$j< \texttt{len(children}(i))$}
\STATE \texttt{Merge}$(i,j+1)$
\ENDIF
\ELSE
\STATE $\widetilde{C} = C^*, s=\abs{K}$
\FOR{$r \in \texttt{children}(i)$}
\IF{$K[r] \cap C^* \neq \emptyset$}
\STATE  $\texttt{parent}(r) = s, \widetilde{C} = \widetilde{C} \cup K[r]$
\ENDIF
\STATE append $\widetilde{C} $ to $K$
\ENDFOR
\STATE $\texttt{parent}(s) = i$
\STATE \texttt{Merge}$(s,0)$
\STATE Within graph $G$, contract $C^*$ to $K[j'][0]$
\STATE \texttt{Merge}$(i,j)$
\ENDIF
\ENDFUNCTION
\end{algorithmic}
\end{algorithm}
The key is to solve the maximum in line \ref{line:max}.
We only need to consider a subgraph $G'$ with node set $V \cap K[i]$.
We denote the function to be maximized as
\begin{equation}
J_T(Z_C) = \frac{w(C)}{\abs{C}-1}
\end{equation}
This comes from the bottom-up approach of info-clustering. We do not need to maximize over $I(Z_C)$. Instead, we maximize over $J_T(Z_C)$.

Consider
\begin{equation}\label{eq:setdt}
g(\lambda) = \min_{C\subset V, t \in C} \{ H(C) + \lambda\abs{C}\}
\end{equation}
where $H(C) = f(C) - \sum_{i\in C} f(\{i\})$. Denote $a_i = f(\{i\}), y^{\lambda}_i = a_i - \lambda$. Then equation \ref{eq:setdt} can be simplified as 
\begin{align}
g(\lambda) &= \min_{C\subset V, t \in C} g_{\lambda}(C) \\
g_{\lambda}(C)  & = f(C) - y^{\lambda}(C)
\end{align}
The function defined in the above equation is piecewise linear about $\lambda$. 
% Its property is explored fully in my nips 2019 paper submission.

\begin{theorem}\label{thm:LastCriticalValue}
The largest turning point of $g(\lambda)$ is denoted as $\gamma_N$, which equals $\max_{C\subset V, t\in C}J_T(Z_C)$
\end{theorem}

The last line segment of $g(\lambda)$ is $\lambda$.
\begin{proof}[Proof of theorem \ref{thm:LastCriticalValue}]
\begin{align*}
\gamma_N & = \max_{C\subset V: \abs{C}>1} J_T(Z_C) \\
& = \min\{\lambda : \lambda \geq \frac{-H(C)}{\abs{C}-1} \textrm{ for all $C\subset V$ and $ t\in C$}\} \\
& = \min\{\lambda : \lambda \leq H(C)+\lambda\abs{C} \textrm{ for all $C\subset V$ and $t \in C$}\} \\
& = \min\{\lambda : \lambda \leq g(\lambda) \} \textrm{ holds for } \abs{C}=1
\end{align*}
\end{proof}

Inner improvement (DT part),
\begin{algorithm}
\caption{}\label{alg:dt_i}
\begin{algorithmic}[1]
\REQUIRE a directed graph $G(V, E)$; edge cost function $c(e)$ for $e\in E$, a given $\lambda$
\ENSURE a partition $\P^*$ which minimize $f[\P] - \lambda \abs{\P}$
\STATE initialize $y_i = -\lambda$ for $ i \in V$, $U = \emptyset, \P = \{\emptyset\}, V' = V$
\WHILE{$U \neq V$}
\STATE pick a node $v \in V\backslash U$
\STATE $A^* = \argmin_{v \in A \subseteq V'} \{ f(A) - \lambda - y(A)\}, a = f(A^*) - y(A^*)$
\IF{$f(V\backslash U) - y(V\backslash U) = a$} \label{alg:judge}
\STATE $A* = V \backslash U$
\ENDIF
\STATE $y_v = y_v + a$
\STATE $U = U \cup A^*$
\STATE $\P= \P[A^*]$
\STATE contract the graph $G$, with $A^*$ to $v$.
\ENDWHILE
\end{algorithmic}
\end{algorithm}
Line \ref{alg:judge} of Algorithm \ref{alg:dt_i} is an early stopping technique.

Algorithm \ref{alg:dt_i} does not speed up the computation significantly. For the traditional greedy Dilworth truncation. the maximum flow algorithm is applied to an increasing set. However, Algorithm \ref{alg:dt_i} is applied to the whole graph at each step. If $\abs{A^*} = 1$ at each step ( which happens when $\P^* = \{\{1\},\dots, \{\abs{V}\}\}$ is the minimum solution ), then Algorithm \ref{alg:dt_i} is slower than the original algorithm.
\end{document}
