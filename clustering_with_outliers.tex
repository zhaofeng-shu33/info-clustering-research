\documentclass{article}
\usepackage{algorithmic}
\begin{document}
Using $\gamma_N$ implicitly assumes inliers come from one class.
If we are required to detect outliers in a multi-class dataset, we can use other critical values of $C_{\gamma}(Z_V)$ starting from the second largest one. 

Assuming the clusters of inliners are of equal size $N$ and the total number of outliers $M$ is less than $N$.
If we know there are $k$ classes, we should choose the critical value $\gamma_{-k}$ as the threshold value.

Actually we do not need to manually choose which threshold to use and in reality it is often the case that we do not know how many classes there are.
An empirical and reasonable way to deal with the situation is given as follows:
We start from the finest partition $\mathcal{P}_{-1}$ and test whether the total number of data (equal to $N+M$) is larger than $2M$. If true, then $k=1$ and $\mathcal{P}_{-1}$ is our choice.
Empirically, $M$ is estimated from $|\mathcal{P}_{-1}|$.

The selection rule for $\mathcal{P}_{-k}$ is as follows:

\begin{algorithmic}
\STATE Let $k=1$
\WHILE{ $ n \leq (k+1) |\mathcal{P}_{-k}|$}
\STATE $k\leftarrow k+1$
\ENDWHILE
\end{algorithmic}

We use $n$ to represent the total number of data. Notice that the condition $ n > (k+1) |\mathcal{P}_{-k}|$ is equivalent
to $N>M$ when there are $k$ clusters and $k$ is small.


\end{document}
